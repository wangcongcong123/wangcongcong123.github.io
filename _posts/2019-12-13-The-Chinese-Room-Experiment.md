---
layout: post
title: Chatbot Explained - The Chinese Room Thought Experiment
---

In this post, I share the Chinese Room Thought Experiment that I played with kids in my [Communication and Outreach](https://sisweb.ucd.ie/usis/!W_HU_MENU.P_PUBLISH?p_tag=MODULE&MODULE=COMP41380) course. 


### Learning Objectives
 * The secrets behind chat bots
 * How machine understands human language


### Introduction

In this activity, the children will learn about how chat bots work and how machine understands human language. This activity basically starts by demonstrating children how the popular chat bot Siri answers human questions. Then the so-called Chinese Room Thought experiment is conducted to ask the children (assume they do not know Chinese) to answer questions written in Chinese with only the rulebook as reference. The purpose of the demonstration and experiment comes to the theory explanation. In the end section, explanations on how machine like Siri understands human language and the limitations of machine understanding human language are summarised for the children.

### Activity Plan

* **Demonstration**

	Demonstrate Siri to the Children and explain who Siri is. There is a pre-recorded video in the [slides](/images/the-chinese-room-thought/slides.pdf). In the video is Siri be asked three questions ([Figure 1](/images/the-chinese-room-thought/questions_to_siri.png)): 1) What is Siri? 2) How old are you? 3) How do say hello in Chinese? Siri seems answer these questions very well. Some questions are thrown out for the children after the demonstration. For example, ask if they know how Siri understands human language. Next, an important question to ask the children is if they know speaking Chinese. Most children may say no honestly. However, it is worth taking a grain of salt at this moment to believe they really don't know Chinese. Here is how the following experiment comes to its role to justify.

	![_config.yml]({{ site.baseurl }}/images/the-chinese-room-thought/questions_to_siri.png)

* **Experiments**

	This is so called The Chinese Room Experiment. In this experiment, divide the children into groups with 2 in each. Each group is offered a rulebook which contains clues of Chinese questions to corresponding answers. There are two parts of the experiment. In the first part, ask the children to turn to page 1 of the rulebook and present them a question card written in Chinese. What the children need to do is to find the corresponding correct answer within 1 minutes with only the rulebookâ€™s page 1 as reference. It is easy to find the answer because the rulebook's first page contains question-answer pairs in the form of IF [a-Chinese-question], THNEN [the answer]. They just need to match the answer with the one in the question card to sort out the correct one ([Figure 2](/images/the-chinese-room-thought/qc_r_p1.png)).

	![_config.yml]({{ site.baseurl }}/images/the-chinese-room-thought/qc_r_p1.png)


	Next, the experiment goes to the second part which is slightly different from the first one. In this part, children need to turn to page 2 of the rulebook which contains clues of so-called Chinese cloze test - filling in the masked blank in a sentence only given the surrounding context words. Now a cloze test question card is presented to the Children. They sort out the question (pick the most likely one out of three choices to fill in the blank) with only the rulebook's page 2 as reference ([Figure 3](/images/the-chinese-room-thought/qc_r_p2.png)). After the two parts, it is the right time for me to say to them: I think you know Chinese because you answer my question cards so correctly. They are probably confused for what I am saying so. Now here is how the explanations come to its role.

	![_config.yml]({{ site.baseurl }}/images/the-chinese-room-thought/qc_r_p2.png)

* Explanation

	The children actually do not know Chinese. The reason I think they know is because they answer my questions well. The secret is that they have the rulebook as reference, namely, they follow the written rules to answer my questions very well. This is exactly the same way how machines like Siri understand human language. That's to say machine understands human language in the way by summarising such a rulebook. How do machines summarise the rulebook? Simply speaking, they learn from large amounts of human-written texts. They learn the grammar rules and patterns in human language statistifcally from the texts. However, the sad news is that the perfect rule book has never existed. Human lanague is so complicated and evolved over time. Our brain are so intelligent so that we always come up with new words, new phrases, or innovative ways of expressing something. This makes machine really difficult to catch up with the human's intelligence. One interesting example is such a sentence: `colorless green ideas sleep furiously`. This sentence makes perfect sense in terms of grammar, but it is nonsense regarding the semnatics. To understand this level of meaning, machine expects further intelligence.   

	To put a vision on the future of machine in understanding human language, it is not that near to the postive outcome. Hence, much work ahead is needed.


Feedback is welcome!

If you have any doubts or any my mistakes you found in the blog, send me an email via [wangcongcongcc@gmail.com](mailto:wangcongcongcc@gmail.com) or you are welcome to talk with me about any NLP relevant questions through [my Twitter account](https://twitter.com/WangcongcongCC).


### References:
1. [Machines Beat Humans on a Reading Test. But Do They Understand?](https://www.quantamagazine.org/machines-beat-humans-on-a-reading-test-but-do-they-understand-20191017)
2. [The Chinese Room Experiment - The Hunt for AI - BBC](https://www.youtube.com/watch?v=D0MD4sRHj1M)
